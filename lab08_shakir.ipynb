{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Recommender System\n",
    "\n",
    "In this assignment, we will study how to do user-based collaborative filtering and item-based collaborative filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_100k = '/Users/omarshakir/Desktop/Movie Reccomender System/ml_100k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "In this assignment, we will use MovieLens-100K dataset. It includes about 100,000 ratings from 1000 users on 1700 movies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1664)\n",
      "(943, 1664)\n"
     ]
    }
   ],
   "source": [
    "# 1. load data\n",
    "# Load training and test data for user-movie ratings and movie information\n",
    "train_df = pd.read_csv('./ml-100k/u1.base',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "test_df = pd.read_csv('./ml-100k/u1.test',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "movie_info = pd.read_csv('./ml-100k/u.item', \n",
    "                          sep='|', names=['movie_id','title'], usecols=[0,1],\n",
    "                          encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Merge movie information with user-movie ratings\n",
    "train_df = pd.merge(movie_info, train_df)\n",
    "test_df = pd.merge(movie_info, test_df)\n",
    "\n",
    "# 2. get the rating matrix. Each row is a user, and each column is a movie.\n",
    "# Convert the merged user-movie ratings to a pivot table for easy use\n",
    "train_df = train_df.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "test_df = test_df.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "# Reindex the training and test data to include all movies and users in both datasets\n",
    "train_df = train_df.reindex(\n",
    "                            index=train_df.index.union(test_df.index), \n",
    "                            columns=train_df.columns.union(test_df.columns) )\n",
    "test_df = test_df.reindex(\n",
    "                            index=train_df.index.union(test_df.index), \n",
    "                            columns=train_df.columns.union(test_df.columns) )\n",
    "\n",
    "# Print the shape of the training and test data\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. User-based CF\n",
    "\n",
    "* Use pearson correlation to get the similarity between different users.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8316716024705649\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "# Replace Nans with row avg\n",
    "train_df['avg'] = train_df.mean(axis=1)\n",
    "train_df_no_nan = train_df.T.fillna(train_df['avg'], axis=0).T\n",
    "\n",
    "# Calculate Pearson similarity\n",
    "pearson_sim_train = 1-pairwise_distances(train_df_no_nan, metric=\"correlation\")\n",
    "\n",
    "# Fit Nearest Neighbors model\n",
    "train_model = NearestNeighbors(n_neighbors=10)\n",
    "train_model.fit(pearson_sim_train)\n",
    "\n",
    "# Get nearest neighbors\n",
    "neighbors_distance, neighbors_ind = train_model.kneighbors()\n",
    "neighbors_ind += 1 # +1 fixes off by one error since ids start at 1 instead of 0\n",
    "\n",
    "# Predict ratings for test data\n",
    "predictions = []\n",
    "actual = []\n",
    "for user_id, row in test_df.iterrows():\n",
    "    for movie, rating in row.items():\n",
    "        if not pd.isnull(rating):\n",
    "            predicted_rating = 0\n",
    "            sum_of_sim = 0\n",
    "            for x in range(0,10):\n",
    "                ngbh_id = neighbors_ind[user_id-1][x]\n",
    "                nghb_rating = train_df.loc[ngbh_id,movie]\n",
    "                if not pd.isnull(nghb_rating):\n",
    "                    nghb_distance = neighbors_distance[user_id-1][x]\n",
    "                    sum_of_sim += nghb_distance\n",
    "                    predicted_rating += nghb_distance*(nghb_rating-train_df.loc[ngbh_id, 'avg'])\n",
    "            if (sum_of_sim != 0):\n",
    "                predicted_rating = predicted_rating/sum_of_sim\n",
    "                predicted_rating += train_df.loc[user_id, 'avg']\n",
    "                predictions.append(predicted_rating)\n",
    "                actual.append(rating)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(predictions, actual)\n",
    "print('MAE: ' + str(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Item-based CF\n",
    "* Use cosine similarity to get the similarity between different items.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.037308373538804\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "ir_train = train_df.T\n",
    "ir_test = test_df.T\n",
    "\n",
    "# Replace Nans with row average\n",
    "ir_train['avg'] = ir_train.mean(axis=1)\n",
    "ir_train_no_nan = ir_train.T.fillna(ir_train['avg'], axis=0).T\n",
    "\n",
    "# Remove rows with no data\n",
    "dropped_rows = ir_train_no_nan[ir_train_no_nan.isna().any(axis=1)]\n",
    "ir_train_no_nan = ir_train_no_nan.drop(dropped_rows.index)\n",
    "ir_test = ir_test.drop(dropped_rows.index)\n",
    "\n",
    "pearson_sim_train = 1-pairwise_distances(ir_train_no_nan, metric=\"cosine\")\n",
    "\n",
    "train_model = NearestNeighbors(n_neighbors=10)\n",
    "train_model.fit(pearson_sim_train)\n",
    "\n",
    "neighbors_distance, neighbors_ind = train_model.kneighbors()\n",
    "neighbors_ind += 1 # +1 fixes off by one error since ids start at 1 instead of 0\n",
    "\n",
    "predictions = []\n",
    "actual = []\n",
    "\n",
    "for movie_id, row in ir_test.iterrows():\n",
    "    item_id = ir_test.index.get_loc(movie_id)\n",
    "    for user, rating in row.items():\n",
    "        if not pd.isnull(rating):\n",
    "            predicted_rating = 0\n",
    "            sum_of_sim = 0\n",
    "            for x in range(0,10):\n",
    "                ngbh_id = neighbors_ind[item_id][x]\n",
    "                nghb_rating = ir_train.iloc[ngbh_id].loc[user]\n",
    "                if not pd.isnull(nghb_rating):\n",
    "                    nghb_distance = neighbors_distance[item_id][x]\n",
    "                    sum_of_sim += nghb_distance\n",
    "                    predicted_rating += nghb_distance*(nghb_rating)\n",
    "            if (sum_of_sim != 0):\n",
    "                predicted_rating = predicted_rating/sum_of_sim\n",
    "                predictions.append(predicted_rating)\n",
    "                actual.append(rating)\n",
    "\n",
    "mae = mean_absolute_error(predictions, actual)\n",
    "print('MAE: ' + str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
